{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center><h2>ALTeGraD 2023<br>Lab Session 3: Transfer learning for NLP</h2> 24 / 10 / 2023<br> Dr. G. Shang, H. Abdine<br><br>\n",
        "\n",
        "\n",
        "<b>Student name:</b> [Victor Gertner]\n",
        "\n",
        "</center>\n",
        "\n",
        "<br><br>\n",
        "In this lab we will:\n",
        "* Implement and pretrain a language model with transformer architecture.\n",
        "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
        "* Compare the performance of the pretrained model to a model trained from scratch.\n",
        " <br>\n",
        "\n",
        "<b>The deadline for this lab is October 31, 2023 11:59 PM.</b> More details about the submission and the architecture for this lab can be found in the handout PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(ntoken,nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid,dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(nhid,nhead,nhid,dropout) #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers,nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src,src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid,nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout)#fill me\n",
        "        self.classifier = ClassificationHead(nhid, nclasses)#fill me\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "        x = self.base(src,src_mask)#fill me\n",
        "        # classifier model\n",
        "        output =self.classifier(x) #fill me\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rhb2gkUhJMR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "036198d0-c138-42f6-8824-ec4ac7037727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of parameters in Language modeling are : 1008100\n",
            "torch.Size([1, 6, 100])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "ntokens = 100 # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "print('The number of parameters in Language modeling are :',sum(p.numel() for p in model.parameters())) #We change the ntokens to 2 here (only for the ouput size and we ahve classification)\n",
        "\n",
        "\n",
        "\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape? : Yes 6 is thesize of the imput dummy and 100 is the number of token!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5qjd26ghWuff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8111a5-b718-43c4-d374-52ff21ccd54f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 18:32:49--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt’\n",
            "\n",
            "dict.txt            100%[===================>] 564.05K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-31 18:32:49 (14.6 MB/s) - ‘dict.txt’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vFdH_-JeFbGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83116d8c-403b-4146-d84e-cd8af47920ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁trop\n"
          ]
        }
      ],
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] =  idx + 4 #Weput + 4 because we have the 4 first already set\n",
        "\n",
        "ind2token = {v:k for (k,v) in token2ind.items()} #fill me\n",
        "\n",
        "print(ind2token[1111])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [0] + [token2ind.get(word,3) for word in sequence]#fill me (constract the input sequence using token2ind, sequence and special tokens)\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            output = output[-1]#fill me\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target =  data[1]#fill me\n",
        "        target = target.to(device)\n",
        "        loss =  criterion(output,target)#fill me, Cross entropy check next cells\n",
        "        #fill me step 3\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
        "        #fill me step 4\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "outputs": [],
      "source": [
        "\n",
        "ntokens = len(ind2token)#fill me # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "outputs": [],
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Bwh3n9xZQy4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefd6100-2669-433a-d5ee-6062d786b1b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 18:32:50--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-10-31 18:32:51 (139 MB/s) - ‘pretraining_subset.txt’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0m11g4ScjZaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90bd50b1-9407-4696-eac0-e3765a77d7ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.31794 | ppl 1507.089\n",
            "| epoch   1 |  1000/ 3125 steps | loss 6.49620 | ppl  662.620\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.20060 | ppl  493.044\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.02759 | ppl  414.716\n",
            "| epoch   1 |  2500/ 3125 steps | loss 5.94024 | ppl  380.025\n",
            "| epoch   1 |  3000/ 3125 steps | loss 5.82019 | ppl  337.036\n",
            "| epoch   2 |   500/ 3125 steps | loss 5.50819 | ppl  246.705\n",
            "| epoch   2 |  1000/ 3125 steps | loss 5.51335 | ppl  247.982\n",
            "| epoch   2 |  1500/ 3125 steps | loss 5.42869 | ppl  227.850\n",
            "| epoch   2 |  2000/ 3125 steps | loss 5.41261 | ppl  224.216\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.37793 | ppl  216.572\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.36854 | ppl  214.549\n"
          ]
        }
      ],
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\", # fill me\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-BcBC6FSkMH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595de606-a6e0-4ca0-d1b3-f31ace316fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 18:37:37--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   303MB/s    in 0.3s    \n",
            "\n",
            "2023-10-31 18:37:40 (303 MB/s) - ‘pretrained_model_4layers.pt’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt')\n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tBRRVsWqlIoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ff04807-a8c8-4664-a781-da5ad9829ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "--2023-10-31 18:37:47--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-31 18:37:47 (26.1 MB/s) - ‘sentencepiece.french.model’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece   # uncomment this if you are using google colab\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "outputs": [],
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind = torch.argmax(out,dim=2)[-1].item() #fill me\n",
        "    return next_token_ind, out\n",
        "\n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "  gene=s.encode_as_pieces(sent)\n",
        "  for i in range(max_len):\n",
        "    next_token_ind, out = infer_next_token(sent)\n",
        "    if next_token_ind == token2ind['<eos>']:\n",
        "      break\n",
        "    gene+= ind2token[next_token_ind]\n",
        "    sent= s.decode_pieces(gene)\n",
        "\n",
        "  return s.decode_pieces(gene)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "f83Nn5nSly4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6ae0528b-6e4d-4f8f-b453-e74d4c3372f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bonjour les gens qui ont été très accueillants et sympathiques.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0K1BZsblmEmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a36689-9f46-4190-969d-4ca11f20cf66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 18:37:47--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm’\n",
            "\n",
            "train.review.spm    100%[===================>]   1.43M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-31 18:37:47 (32.2 MB/s) - ‘train.review.spm’ saved [1495960/1495960]\n",
            "\n",
            "--2023-10-31 18:37:47--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label’\n",
            "\n",
            "train.label         100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-31 18:37:48 (59.9 MB/s) - ‘train.label’ saved [3200/3200]\n",
            "\n",
            "--2023-10-31 18:37:48--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm’\n",
            "\n",
            "test.review.spm     100%[===================>]   1.78M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-10-31 18:37:48 (35.2 MB/s) - ‘test.review.spm’ saved [1864544/1864544]\n",
            "\n",
            "--2023-10-31 18:37:48--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label’\n",
            "\n",
            "test.label          100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-31 18:37:48 (70.8 MB/s) - ‘test.label’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "outputs": [],
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    model.eval()\n",
        "    cor = 0\n",
        "    tot = 0\n",
        "    for data in data_loader:\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(device)\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask)\n",
        "        output = output[-1] # we have to do that in order to have classification\n",
        "        target = data[1].to(device)\n",
        "        predicted = torch.argmax(output,dim=1) #we have the batchsize in 0\n",
        "        tot += data[1].size(0) # we take each time the batchsize\n",
        "        cor += (predicted == target).sum().item()\n",
        "    return cor/tot\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "outputs": [],
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NThjnzMAkUYr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-xclMCpnVpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328c9d2f-0edf-4818-e285-58beda257de8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.76995 | ppl    2.160\n",
            "| epoch   1 |   100/  200 steps | loss 0.72084 | ppl    2.056\n",
            "| epoch   1 |   150/  200 steps | loss 0.75533 | ppl    2.128\n",
            "| epoch   2 |    50/  200 steps | loss 0.68913 | ppl    1.992\n",
            "| epoch   2 |   100/  200 steps | loss 0.59755 | ppl    1.818\n",
            "| epoch   2 |   150/  200 steps | loss 0.58731 | ppl    1.799\n",
            "| epoch   3 |    50/  200 steps | loss 0.45120 | ppl    1.570\n",
            "| epoch   3 |   100/  200 steps | loss 0.35490 | ppl    1.426\n",
            "| epoch   3 |   150/  200 steps | loss 0.37316 | ppl    1.452\n",
            "| epoch   4 |    50/  200 steps | loss 0.19121 | ppl    1.211\n",
            "| epoch   4 |   100/  200 steps | loss 0.15867 | ppl    1.172\n",
            "| epoch   4 |   150/  200 steps | loss 0.17495 | ppl    1.191\n",
            "| epoch   5 |    50/  200 steps | loss 0.04324 | ppl    1.044\n",
            "| epoch   5 |   100/  200 steps | loss 0.03397 | ppl    1.035\n",
            "| epoch   5 |   150/  200 steps | loss 0.01465 | ppl    1.015\n",
            "| epoch   6 |    50/  200 steps | loss 0.00775 | ppl    1.008\n",
            "| epoch   6 |   100/  200 steps | loss 0.00348 | ppl    1.003\n",
            "| epoch   6 |   150/  200 steps | loss 0.00029 | ppl    1.000\n",
            "| epoch   7 |    50/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   7 |   100/  200 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch   7 |   150/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   8 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   100/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   8 |   150/  200 steps | loss 0.00012 | ppl    1.000\n",
            "| epoch   9 |    50/  200 steps | loss 0.00010 | ppl    1.000\n",
            "| epoch   9 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  14 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.81730 | ppl    2.264\n",
            "| epoch   1 |   100/  200 steps | loss 0.63163 | ppl    1.881\n",
            "| epoch   1 |   150/  200 steps | loss 0.65261 | ppl    1.921\n",
            "| epoch   2 |    50/  200 steps | loss 0.44816 | ppl    1.565\n",
            "| epoch   2 |   100/  200 steps | loss 0.50873 | ppl    1.663\n",
            "| epoch   2 |   150/  200 steps | loss 0.49748 | ppl    1.645\n",
            "| epoch   3 |    50/  200 steps | loss 0.41757 | ppl    1.518\n",
            "| epoch   3 |   100/  200 steps | loss 0.35243 | ppl    1.423\n",
            "| epoch   3 |   150/  200 steps | loss 0.35921 | ppl    1.432\n",
            "| epoch   4 |    50/  200 steps | loss 0.23086 | ppl    1.260\n",
            "| epoch   4 |   100/  200 steps | loss 0.35297 | ppl    1.423\n",
            "| epoch   4 |   150/  200 steps | loss 0.29835 | ppl    1.348\n",
            "| epoch   5 |    50/  200 steps | loss 0.18650 | ppl    1.205\n",
            "| epoch   5 |   100/  200 steps | loss 0.26798 | ppl    1.307\n",
            "| epoch   5 |   150/  200 steps | loss 0.26907 | ppl    1.309\n",
            "| epoch   6 |    50/  200 steps | loss 0.08818 | ppl    1.092\n",
            "| epoch   6 |   100/  200 steps | loss 0.05552 | ppl    1.057\n",
            "| epoch   6 |   150/  200 steps | loss 0.23503 | ppl    1.265\n",
            "| epoch   7 |    50/  200 steps | loss 0.03301 | ppl    1.034\n",
            "| epoch   7 |   100/  200 steps | loss 0.04913 | ppl    1.050\n",
            "| epoch   7 |   150/  200 steps | loss 0.08592 | ppl    1.090\n",
            "| epoch   8 |    50/  200 steps | loss 0.01629 | ppl    1.016\n",
            "| epoch   8 |   100/  200 steps | loss 0.01517 | ppl    1.015\n",
            "| epoch   8 |   150/  200 steps | loss 0.05839 | ppl    1.060\n",
            "| epoch   9 |    50/  200 steps | loss 0.00765 | ppl    1.008\n",
            "| epoch   9 |   100/  200 steps | loss 0.00668 | ppl    1.007\n",
            "| epoch   9 |   150/  200 steps | loss 0.03607 | ppl    1.037\n",
            "| epoch  10 |    50/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch  10 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   150/  200 steps | loss 0.00006 | ppl    1.000\n",
            "| epoch  11 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   100/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.00023 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  15 |    50/  200 steps | loss 0.00073 | ppl    1.001\n",
            "| epoch  15 |   100/  200 steps | loss 0.01376 | ppl    1.014\n",
            "| epoch  15 |   150/  200 steps | loss 0.00008 | ppl    1.000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCpBIdTHojm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "0dbef6c7-c208-49fa-e3f1-db40ea7b36b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "abs = [ i for i in range (1,epochs +1)]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(abs,from_scratch_valid_acc,label = 'training from scratch')\n",
        "plt.plot(abs,pretrained_valid_acc,label = 'pretrained model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.plot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f3cfdeab8dd8f9900bd16266619de191cf0f5e09365d74b1fba1714dce58066"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}